{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import json\n",
        "import re\n",
        "from typing import List, Dict, Optional, Any\n",
        "import requests\n",
        "\n",
        "# Groq API Key\n",
        "GROQ_API_KEY = \"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\"\n",
        "\n",
        "# Base URL per Groq's OpenAI-compatible interface\n",
        "GROQ_BASE_URL = \"https://api.groq.com/openai/v1\"\n",
        "# Chat completions endpoint\n",
        "CHAT_COMPLETIONS_URL = f\"{GROQ_BASE_URL}/chat/completions\"\n",
        "\n",
        "DEFAULT_MODEL = \"openai/gpt-oss-20b\"\n",
        "\n",
        "HEADERS = {\n",
        "    \"Authorization\": f\"Bearer {GROQ_API_KEY}\",\n",
        "    \"Content-Type\": \"application/json\",\n",
        "}\n",
        "\n",
        "# 2. Low-level Groq/OpenAI-compatible wrapper\n",
        "\n",
        "def groq_chat_request(payload, url=CHAT_COMPLETIONS_URL, headers=HEADERS, timeout=30):\n",
        "    \"\"\"Send a request to Groq's chat/completions API.\"\"\"\n",
        "    # Remove unsupported fields\n",
        "    payload.pop(\"max_output_tokens\", None)\n",
        "\n",
        "    resp = requests.post(url, headers=headers, json=payload, timeout=timeout)\n",
        "    resp_json = resp.json()\n",
        "\n",
        "    if not resp.ok:\n",
        "        err = resp_json.get('error') or resp_json\n",
        "        raise RuntimeError(f\"Groq API error ({resp.status_code}): {err}\")\n",
        "\n",
        "    return resp_json\n",
        "\n",
        "# 3. Conversation Manager with summarization & truncation\n",
        "\n",
        "class ConversationManager:\n",
        "    def __init__(self,\n",
        "                 model: str = DEFAULT_MODEL,\n",
        "                 summarize_after_k: int = 3,\n",
        "                 summary_prefix: str = \"Conversation summary:\",\n",
        "                 retain_recent_turns: int = 3):\n",
        "        self.model = model\n",
        "        self.history: List[Dict[str, str]] = []\n",
        "        self.run_count = 0\n",
        "        self.summarize_after_k = summarize_after_k\n",
        "        self.summary_prefix = summary_prefix\n",
        "        self.retain_recent_turns = retain_recent_turns\n",
        "\n",
        "    def add_user_message(self, content: str):\n",
        "        self.history.append({\"role\": \"user\", \"content\": content})\n",
        "\n",
        "    def add_assistant_message(self, content: str):\n",
        "        self.history.append({\"role\": \"assistant\", \"content\": content})\n",
        "\n",
        "    def get_history(self):\n",
        "        return list(self.history)\n",
        "\n",
        "    def truncate_history(self, last_n_turns: Optional[int] = None,\n",
        "                         max_chars: Optional[int] = None,\n",
        "                         max_words: Optional[int] = None) -> List[Dict[str, str]]:\n",
        "        messages = list(self.history)\n",
        "\n",
        "        if last_n_turns is not None:\n",
        "            truncated = messages[-last_n_turns:]\n",
        "        else:\n",
        "            truncated = messages\n",
        "\n",
        "        if max_chars is not None:\n",
        "            while sum(len(m['content']) for m in truncated) > max_chars and len(truncated) > 1:\n",
        "                truncated.pop(0)\n",
        "\n",
        "        if max_words is not None:\n",
        "            while sum(len(m['content'].split()) for m in truncated) > max_words and len(truncated) > 1:\n",
        "                truncated.pop(0)\n",
        "\n",
        "        return truncated\n",
        "\n",
        "    def perform_summary(self, temperature: float = 0.0, max_tokens: int = 400) -> str:\n",
        "        if not self.history:\n",
        "            return \"\"\n",
        "\n",
        "        prompt_parts = [\n",
        "            \"You are a helpful summarizer. Produce a concise summary of the conversation below.\\n\",\n",
        "            \"The summary should: 1) capture user intents, 2) surface important facts/requests, 3) be short (3-6 bullets or a short paragraph).\",\n",
        "            \"Do not invent facts. If something is ambiguous, mark it as uncertain.\\n\\n\",\n",
        "            \"Conversation:\\n\"\n",
        "        ]\n",
        "\n",
        "        for m in self.history:\n",
        "            role = m['role']\n",
        "            content = m['content']\n",
        "            prompt_parts.append(f\"[{role}] {content}\\n\")\n",
        "\n",
        "        prompt = \"\\n\".join(prompt_parts)\n",
        "\n",
        "        payload = {\n",
        "            \"model\": self.model,\n",
        "            \"messages\": [\n",
        "                {\"role\": \"system\", \"content\": \"You summarize conversations concisely.\"},\n",
        "                {\"role\": \"user\", \"content\": prompt}\n",
        "            ],\n",
        "            \"max_output_tokens\": max_tokens,\n",
        "            \"temperature\": temperature,\n",
        "        }\n",
        "\n",
        "        try:\n",
        "            resp = groq_chat_request(payload)\n",
        "            choices = resp.get('choices') or []\n",
        "            if choices:\n",
        "                summary = choices[0].get('message', {}).get('content', '').strip()\n",
        "            else:\n",
        "                summary = ''\n",
        "        except Exception as e:\n",
        "            print('Warning: API summarization failed:', str(e))\n",
        "            recent_text = '\\n'.join([m['content'] for m in self.history[-6:]])\n",
        "            summary = 'Fallback summary (truncated): ' + (recent_text[:800] + '...' if len(recent_text) > 800 else recent_text)\n",
        "\n",
        "        self.history = [{\"role\": \"system\", \"content\": f\"{self.summary_prefix}\\n{summary}\"}] + self.history[-self.retain_recent_turns:]\n",
        "\n",
        "        return summary\n",
        "\n",
        "    def step(self, user_message: str, generate_assistant_reply: bool = True, **reply_kwargs) -> Dict[str, Any]:\n",
        "        self.run_count += 1\n",
        "        self.add_user_message(user_message)\n",
        "\n",
        "        assistant_reply = None\n",
        "        if generate_assistant_reply:\n",
        "            try:\n",
        "                truncated = self.truncate_history(last_n_turns=12)\n",
        "                payload = {\n",
        "                    \"model\": self.model,\n",
        "                    \"messages\": truncated,\n",
        "                    \"max_output_tokens\": reply_kwargs.get('max_output_tokens', 200),\n",
        "                    \"temperature\": reply_kwargs.get('temperature', 0.2),\n",
        "                }\n",
        "                resp = groq_chat_request(payload)\n",
        "                choices = resp.get('choices') or []\n",
        "                if choices:\n",
        "                    assistant_reply = choices[0].get('message', {}).get('content', '').strip()\n",
        "                else:\n",
        "                    assistant_reply = \"\"\n",
        "            except Exception as e:\n",
        "                assistant_reply = f\"(assistant generation failed: {e})\"\n",
        "\n",
        "            self.add_assistant_message(assistant_reply)\n",
        "\n",
        "        summary = None\n",
        "        if self.summarize_after_k and self.run_count % self.summarize_after_k == 0:\n",
        "            summary = self.perform_summary()\n",
        "\n",
        "        return {\"assistant_reply\": assistant_reply, \"summary\": summary}\n",
        "\n",
        "# 4. Demonstration: Task 1 — conversation management\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    print(\"\\n=== Task 1: Conversation Manager with Periodic Summarization ===\\n\")\n",
        "\n",
        "    cm = ConversationManager(model=DEFAULT_MODEL, summarize_after_k=3, retain_recent_turns=2)\n",
        "\n",
        "    sample_messages = [\n",
        "        \"Hi, I'm trying to set up fire alarm sensors in a 3-floor building. What's the best placement?\",\n",
        "        \"We have classrooms and a server room; each floor is approx 1500 sq ft.\",\n",
        "        \"Do I need special detectors near the kitchen area?\",\n",
        "        \"Also, what's the maintenance schedule for smoke detectors in a school?\",\n",
        "        \"What are the approximate costs for a basic system per floor?\",\n",
        "        \"Can you provide a checklist for monthly inspection?\",\n",
        "        \"We might have a lab with chemicals; any special recommendations?\",\n",
        "        \"Who can certify installation in Pune, India?\",\n",
        "        \"Thanks — also what's the warranty period for typical detectors?\"\n",
        "    ]\n",
        "\n",
        "    for i, msg in enumerate(sample_messages, 1):\n",
        "        print(f\"-- Run {i}: user -> {msg}\")\n",
        "        out = cm.step(msg, generate_assistant_reply=False)\n",
        "        if out['summary']:\n",
        "            print(\"\\n[Summarization triggered]\")\n",
        "            print(out['summary'])\n",
        "            print(\"\\nCurrent compacted history:\")\n",
        "            for m in cm.get_history():\n",
        "                print(f\"  - ({m['role']}) {m['content'][:200]}\")\n",
        "        else:\n",
        "            print(\"(no summarization this run)\")\n",
        "\n",
        "# 5. Task 2 — JSON Schema Extraction\n",
        "PERSON_SCHEMA = {\n",
        "    \"type\": \"object\",\n",
        "    \"properties\": {\n",
        "        \"name\": {\"type\": \"string\"},\n",
        "        \"email\": {\"type\": \"string\"},\n",
        "        \"phone\": {\"type\": \"string\"},\n",
        "        \"location\": {\"type\": \"string\"},\n",
        "        \"age\": {\"type\": \"integer\"}\n",
        "    }\n",
        "}\n",
        "\n",
        "FUNCTION_DEF = [\n",
        "    {\n",
        "        \"name\": \"extract_person_info\",\n",
        "        \"description\": \"Extract person information\",\n",
        "        \"parameters\": PERSON_SCHEMA\n",
        "    }\n",
        "]\n",
        "\n",
        "EMAIL_RE = re.compile(r\"[^@\\s]+@[^@\\s]+\\.[^@\\s]+\")\n",
        "PHONE_RE = re.compile(r\"^[0-9 \\-+()]{6,}$\")\n",
        "\n",
        "def validate_person_info(d: dict) -> (bool, List[str]):\n",
        "    errs = []\n",
        "    if not isinstance(d, dict):\n",
        "        return False, [\"Payload is not an object\"]\n",
        "\n",
        "    if 'name' in d and not isinstance(d['name'], str):\n",
        "        errs.append(\"name must be a string\")\n",
        "    if 'email' in d and (not isinstance(d['email'], str) or not EMAIL_RE.search(d['email'])):\n",
        "        errs.append(\"email is missing or malformed\")\n",
        "    if 'phone' in d and (not isinstance(d['phone'], str) or not PHONE_RE.search(d['phone'])):\n",
        "        errs.append(\"phone is missing or malformed\")\n",
        "    if 'location' in d and not isinstance(d['location'], str):\n",
        "        errs.append(\"location must be a string\")\n",
        "    if 'age' in d:\n",
        "        try:\n",
        "            if not (isinstance(d['age'], int) and 0 <= d['age'] <= 120):\n",
        "                errs.append(\"age must be an integer between 0 and 120\")\n",
        "        except Exception:\n",
        "            errs.append(\"age must be an integer\")\n",
        "\n",
        "    return (len(errs) == 0), errs\n",
        "\n",
        "SAMPLE_CHATS = [\n",
        "    \"Hey, I'm Rahul Sharma. My email is rahul.sharma@example.com and my phone is +91 98765 43210. I'm in Pune and 29 years old.\",\n",
        "    \"Contact: Mira (mira_work@company.org). Phone 555-0199. Location: Mumbai. Age: 34.\",\n",
        "    \"Just a note — John Doe, john.doe@mail.com, 44, Delhi. Reach at 09988776655.\"\n",
        "]\n",
        "\n",
        "def extract_info_from_chat(chat_text: str, model: str = DEFAULT_MODEL, max_output_tokens: int = 200):\n",
        "    payload = {\n",
        "        \"model\": model,\n",
        "        \"messages\": [{\"role\": \"user\", \"content\": f\"Extract personal info from this text: {chat_text}\"}],\n",
        "        \"functions\": FUNCTION_DEF,\n",
        "        \"function_call\": {\"name\": \"extract_person_info\"},\n",
        "        \"max_output_tokens\": max_output_tokens,\n",
        "        \"temperature\": 0.0\n",
        "    }\n",
        "\n",
        "    resp = groq_chat_request(payload)\n",
        "    try:\n",
        "        choices = resp.get('choices', [])\n",
        "        if not choices:\n",
        "            raise RuntimeError(\"No choices in response\")\n",
        "\n",
        "        message = choices[0].get('message', {})\n",
        "        func_call = message.get('function_call')\n",
        "        if not func_call:\n",
        "            content = message.get('content', '')\n",
        "            args = _extract_json_from_text(content)\n",
        "        else:\n",
        "            args_text = func_call.get('arguments', '')\n",
        "            args = json.loads(args_text) if args_text else {}\n",
        "\n",
        "        valid, errors = validate_person_info(args)\n",
        "        return {\"raw\": args, \"valid\": valid, \"errors\": errors}\n",
        "\n",
        "    except Exception as e:\n",
        "        return {\"raw\": None, \"valid\": False, \"errors\": [str(e)], \"resp\": resp}\n",
        "\n",
        "def _extract_json_from_text(text: str):\n",
        "    try:\n",
        "        start = text.index(\"{\")\n",
        "        end = text.rindex(\"}\")\n",
        "        snippet = text[start:end+1]\n",
        "        return json.loads(snippet)\n",
        "    except Exception:\n",
        "        return {}\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    print(\"\\n=== Task 2: JSON Schema Extraction ===\\n\")\n",
        "    for i, chat in enumerate(SAMPLE_CHATS, 1):\n",
        "        print(f\"Sample {i}: {chat}\")\n",
        "        out = extract_info_from_chat(chat)\n",
        "        print(\"Parsed result:\", json.dumps(out['raw'], indent=2))\n",
        "        print(\"Valid?\", out['valid'], \"Errors:\", out['errors'])\n",
        "        print(\"---\\n\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wa9SosIhMZWR",
        "outputId": "52dee8fe-eaae-4a39-c431-785071a5285b"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Task 1: Conversation Manager with Periodic Summarization ===\n",
            "\n",
            "-- Run 1: user -> Hi, I'm trying to set up fire alarm sensors in a 3-floor building. What's the best placement?\n",
            "(no summarization this run)\n",
            "-- Run 2: user -> We have classrooms and a server room; each floor is approx 1500 sq ft.\n",
            "(no summarization this run)\n",
            "-- Run 3: user -> Do I need special detectors near the kitchen area?\n",
            "\n",
            "[Summarization triggered]\n",
            "- User wants guidance on optimal placement of fire alarm sensors in a 3‑floor building (≈1500 sq ft per floor).  \n",
            "- Building contains classrooms and a server room.  \n",
            "- User asks whether special detectors are required near the kitchen area.\n",
            "\n",
            "Current compacted history:\n",
            "  - (system) Conversation summary:\n",
            "- User wants guidance on optimal placement of fire alarm sensors in a 3‑floor building (≈1500 sq ft per floor).  \n",
            "- Building contains classrooms and a server room.  \n",
            "- User asks \n",
            "  - (user) We have classrooms and a server room; each floor is approx 1500 sq ft.\n",
            "  - (user) Do I need special detectors near the kitchen area?\n",
            "-- Run 4: user -> Also, what's the maintenance schedule for smoke detectors in a school?\n",
            "(no summarization this run)\n",
            "-- Run 5: user -> What are the approximate costs for a basic system per floor?\n",
            "(no summarization this run)\n",
            "-- Run 6: user -> Can you provide a checklist for monthly inspection?\n",
            "\n",
            "[Summarization triggered]\n",
            "- User wants guidance on optimal placement of fire alarm sensors in a 3‑floor building (~1500 sq ft per floor) that includes classrooms and a server room.  \n",
            "- User asks whether special detectors are required near the kitchen area.  \n",
            "- User requests information on the maintenance schedule for smoke detectors in a school.  \n",
            "- User wants approximate cost estimates for a basic system per floor.  \n",
            "- User asks for a checklist for monthly inspection.\n",
            "\n",
            "Current compacted history:\n",
            "  - (system) Conversation summary:\n",
            "- User wants guidance on optimal placement of fire alarm sensors in a 3‑floor building (~1500 sq ft per floor) that includes classrooms and a server room.  \n",
            "- User asks whether s\n",
            "  - (user) What are the approximate costs for a basic system per floor?\n",
            "  - (user) Can you provide a checklist for monthly inspection?\n",
            "-- Run 7: user -> We might have a lab with chemicals; any special recommendations?\n",
            "(no summarization this run)\n",
            "-- Run 8: user -> Who can certify installation in Pune, India?\n",
            "(no summarization this run)\n",
            "-- Run 9: user -> Thanks — also what's the warranty period for typical detectors?\n",
            "\n",
            "[Summarization triggered]\n",
            "- User seeks guidance on optimal placement of fire‑alarm sensors in a 3‑floor building (~1500 sq ft per floor) that includes classrooms, a server room, and a kitchen area.  \n",
            "- Requests:  \n",
            "  1. Approximate cost estimates for a basic system per floor.  \n",
            "  2. A checklist for monthly inspection.  \n",
            "  3. Special recommendations for a lab with chemicals.  \n",
            "  4. Information on who can certify installation in Pune, India.  \n",
            "  5. Warranty period for typical detectors.  \n",
            "- The user also inquires whether special detectors are required near the kitchen and about the maintenance schedule for smoke detectors in a school.\n",
            "\n",
            "Current compacted history:\n",
            "  - (system) Conversation summary:\n",
            "- User seeks guidance on optimal placement of fire‑alarm sensors in a 3‑floor building (~1500 sq ft per floor) that includes classrooms, a server room, and a kitchen area.  \n",
            "- Re\n",
            "  - (user) Who can certify installation in Pune, India?\n",
            "  - (user) Thanks — also what's the warranty period for typical detectors?\n",
            "\n",
            "=== Task 2: JSON Schema Extraction ===\n",
            "\n",
            "Sample 1: Hey, I'm Rahul Sharma. My email is rahul.sharma@example.com and my phone is +91 98765 43210. I'm in Pune and 29 years old.\n",
            "Parsed result: {\n",
            "  \"age\": 29,\n",
            "  \"email\": \"rahul.sharma@example.com\",\n",
            "  \"location\": \"Pune\",\n",
            "  \"name\": \"Rahul Sharma\",\n",
            "  \"phone\": \"+91 98765 43210\"\n",
            "}\n",
            "Valid? True Errors: []\n",
            "---\n",
            "\n",
            "Sample 2: Contact: Mira (mira_work@company.org). Phone 555-0199. Location: Mumbai. Age: 34.\n",
            "Parsed result: {\n",
            "  \"age\": 34,\n",
            "  \"email\": \"mira_work@company.org\",\n",
            "  \"location\": \"Mumbai\",\n",
            "  \"name\": \"Mira\",\n",
            "  \"phone\": \"555-0199\"\n",
            "}\n",
            "Valid? True Errors: []\n",
            "---\n",
            "\n",
            "Sample 3: Just a note — John Doe, john.doe@mail.com, 44, Delhi. Reach at 09988776655.\n",
            "Parsed result: {\n",
            "  \"age\": 44,\n",
            "  \"email\": \"john.doe@mail.com\",\n",
            "  \"location\": \"Delhi\",\n",
            "  \"name\": \"John Doe\",\n",
            "  \"phone\": \"09988776655\"\n",
            "}\n",
            "Valid? True Errors: []\n",
            "---\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wNt-DWZJZvr_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}